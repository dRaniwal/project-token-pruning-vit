{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9abea3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-08T12:31:25.733299Z",
     "iopub.status.busy": "2025-12-08T12:31:25.733094Z",
     "iopub.status.idle": "2025-12-08T12:31:35.112872Z",
     "shell.execute_reply": "2025-12-08T12:31:35.111749Z"
    },
    "papermill": {
     "duration": 9.38387,
     "end_time": "2025-12-08T12:31:35.114288",
     "exception": false,
     "start_time": "2025-12-08T12:31:25.730418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354df930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T12:31:35.119061Z",
     "iopub.status.busy": "2025-12-08T12:31:35.118713Z",
     "iopub.status.idle": "2025-12-08T12:31:35.123021Z",
     "shell.execute_reply": "2025-12-08T12:31:35.122257Z"
    },
    "papermill": {
     "duration": 0.007809,
     "end_time": "2025-12-08T12:31:35.124125",
     "exception": false,
     "start_time": "2025-12-08T12:31:35.116316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG = 48\n",
    "PATCH = 4\n",
    "DIM = 512\n",
    "DEPTH = 8\n",
    "HEADS = 8\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "LR = 3e-4\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f8bf8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T12:31:35.128000Z",
     "iopub.status.busy": "2025-12-08T12:31:35.127566Z",
     "iopub.status.idle": "2025-12-08T12:31:35.138870Z",
     "shell.execute_reply": "2025-12-08T12:31:35.138384Z"
    },
    "papermill": {
     "duration": 0.014436,
     "end_time": "2025-12-08T12:31:35.139922",
     "exception": false,
     "start_time": "2025-12-08T12:31:35.125486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = (dim // heads) ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim*3)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        H = self.heads\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, H, C//H)\n",
    "        q, k, v = qkv.unbind(2)\n",
    "        q = q.permute(0,3,1,2)\n",
    "        k = k.permute(0,3,1,2)\n",
    "        v = v.permute(0,3,1,2)\n",
    "\n",
    "        attn = (q @ k.transpose(-2,-1)) * self.scale\n",
    "        attn = attn.softmax(-1)\n",
    "\n",
    "        out = (attn @ v).transpose(1,2).reshape(B, N, C)\n",
    "        return self.proj(out), attn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim*4)\n",
    "        self.fc2 = nn.Linear(dim*4, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.gelu(self.fc1(x)))\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, heads):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = Attention(dim, heads)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp  = MLP(dim)\n",
    "\n",
    "    def forward(self, x, return_attn=False):\n",
    "        a, attn = self.attn(self.norm1(x))\n",
    "        x = x + a\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        if return_attn:\n",
    "            return x, attn\n",
    "        return x\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(3, DIM, PATCH, PATCH)\n",
    "        N = (IMG // PATCH)**2\n",
    "        self.cls = nn.Parameter(torch.zeros(1,1,DIM))\n",
    "        self.pos = nn.Parameter(torch.zeros(1,1+N,DIM))\n",
    "        self.blocks = nn.ModuleList([Block(DIM, HEADS) for _ in range(DEPTH)])\n",
    "        self.norm = nn.LayerNorm(DIM)\n",
    "        self.head = nn.Linear(DIM, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = self.patch_embed(x).flatten(2).transpose(1,2)\n",
    "        x = torch.cat([self.cls.expand(B,-1,-1), x], dim=1)\n",
    "        x = x + self.pos[:, :x.size(1), :]\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        return self.head(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c29cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T12:31:35.143698Z",
     "iopub.status.busy": "2025-12-08T12:31:35.143459Z",
     "iopub.status.idle": "2025-12-08T12:31:40.342072Z",
     "shell.execute_reply": "2025-12-08T12:31:40.341264Z"
    },
    "papermill": {
     "duration": 5.201975,
     "end_time": "2025-12-08T12:31:40.343301",
     "exception": false,
     "start_time": "2025-12-08T12:31:35.141326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:01<00:00, 86.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "train_tf = T.Compose([\n",
    "    T.RandomResizedCrop(48, scale=(0.8,1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor()\n",
    "])\n",
    "test_tf = T.Compose([T.Resize(48), T.ToTensor()])\n",
    "\n",
    "train_set = datasets.CIFAR10(\n",
    "    root=\"./data\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "test_set = datasets.CIFAR10(\n",
    "    root=\"./data\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=test_tf\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_set,  batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "print(len(train_set), len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40ccd50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T12:31:40.350023Z",
     "iopub.status.busy": "2025-12-08T12:31:40.349793Z",
     "iopub.status.idle": "2025-12-08T13:31:07.899981Z",
     "shell.execute_reply": "2025-12-08T13:31:07.899019Z"
    },
    "papermill": {
     "duration": 3567.794311,
     "end_time": "2025-12-08T13:31:08.140535",
     "exception": false,
     "start_time": "2025-12-08T12:31:40.346224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BASELINE TRAINING ================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 summary: time=5.64 min  train_loss=1.8552  val_acc=46.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 summary: time=5.95 min  train_loss=1.3116  val_acc=57.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 summary: time=5.96 min  train_loss=1.1278  val_acc=62.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 summary: time=5.97 min  train_loss=1.0178  val_acc=63.55%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 summary: time=5.98 min  train_loss=0.9595  val_acc=66.44%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 summary: time=5.98 min  train_loss=0.8908  val_acc=68.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 summary: time=5.99 min  train_loss=0.8536  val_acc=67.67%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 summary: time=5.99 min  train_loss=0.8144  val_acc=68.49%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 summary: time=5.99 min  train_loss=0.7761  val_acc=71.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 summary: time=5.99 min  train_loss=0.7477  val_acc=71.68%\n",
      "\n",
      "Total training time: 59.45 min\n",
      "Saved baseline model → vit_baseline.pth\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------------------\n",
    "#  BASELINE MODEL + OPTIMIZER\n",
    "# ---------------------------------------\n",
    "model = ViT().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "#  TRAIN ONE EPOCH  (with tqdm)\n",
    "# ---------------------------------------\n",
    "def train_one_epoch_baseline(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"[BASELINE] Training\", leave=False)\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / total_samples\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "#  TEST ACCURACY\n",
    "# ---------------------------------------\n",
    "@torch.no_grad()\n",
    "def eval_acc_baseline(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in tqdm(loader, desc=\"[BASELINE] Eval\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x).argmax(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "#  FULL TRAINING LOOP (MATCHES PRUNED FORMAT)\n",
    "# ---------------------------------------\n",
    "print(\"\\n================ BASELINE TRAINING ================\\n\")\n",
    "\n",
    "overall_start = time.time()\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    train_loss = train_one_epoch_baseline(model, train_loader)\n",
    "    val_acc = eval_acc_baseline(model, test_loader)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch {epoch}/10 summary: time={epoch_time/60:.2f} min  train_loss={train_loss:.4f}  val_acc={val_acc*100:.2f}%\\n\")\n",
    "\n",
    "overall_time = time.time() - overall_start\n",
    "print(f\"Total training time: {overall_time/60:.2f} min\")\n",
    "\n",
    "torch.save(model.state_dict(), \"vit_baseline.pth\")\n",
    "print(\"Saved baseline model → vit_baseline.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 140376581,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3588.506032,
   "end_time": "2025-12-08T13:31:10.392432",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-08T12:31:21.886400",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
